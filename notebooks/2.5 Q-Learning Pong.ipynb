{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da01c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcf362",
   "metadata": {},
   "source": [
    "### Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c72e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongAgent:\n",
    "    \n",
    "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        # Creamos la tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        \n",
    "        # Damos un paso aleatorio...\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "        \n",
    "        # o tomaremos el mejor paso...\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            # tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "\n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    "\n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    "\n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    "\n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d768f",
   "metadata": {},
   "source": [
    "### Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b072c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    "\n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    "\n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    "\n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    "\n",
    "        self.avanza_frame()\n",
    "\n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    "\n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    "\n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    "\n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    "\n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    "\n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    "\n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048368a",
   "metadata": {},
   "source": [
    "### Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fbb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    "\n",
    "    if game is None:\n",
    "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
    "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    "\n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    "\n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "    \n",
    "    return learner, game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b677df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin new Train!\n",
      "-- Partidas[ 500 ] Avg.Puntos[ 19 ]  AVG Steps[ 235 ] Max Score[ 140 ]\n",
      "-- Partidas[ 1000 ] Avg.Puntos[ 23 ]  AVG Steps[ 250 ] Max Score[ 150 ]\n",
      "-- Partidas[ 1500 ] Avg.Puntos[ 27 ]  AVG Steps[ 262 ] Max Score[ 330 ]\n",
      "-- Partidas[ 2000 ] Avg.Puntos[ 32 ]  AVG Steps[ 280 ] Max Score[ 330 ]\n",
      "-- Partidas[ 2500 ] Avg.Puntos[ 34 ]  AVG Steps[ 287 ] Max Score[ 360 ]\n",
      "-- Partidas[ 3000 ] Avg.Puntos[ 38 ]  AVG Steps[ 301 ] Max Score[ 630 ]\n",
      "-- Partidas[ 3500 ] Avg.Puntos[ 42 ]  AVG Steps[ 314 ] Max Score[ 630 ]\n",
      "-- Partidas[ 4000 ] Avg.Puntos[ 46 ]  AVG Steps[ 328 ] Max Score[ 630 ]\n",
      "-- Partidas[ 4500 ] Avg.Puntos[ 50 ]  AVG Steps[ 339 ] Max Score[ 630 ]\n",
      "Partidas[ 4999 ] Avg.Puntos[ 51 ] Max score[ 670 ] en partida[ 4925 ]\n"
     ]
    }
   ],
   "source": [
    "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddda3489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner2 = PongAgent(game, policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3cc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
